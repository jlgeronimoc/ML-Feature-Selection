{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardogr07/Machine-Learning-Basics/blob/main/src/1_Feature_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqd6YFojxrTG"
      },
      "source": [
        "# Tutorial: Using Forward Stepwise for Feature Selection\n",
        "In this tutorial, we will demonstrate how to use Forward Stepwise methods for feature selection with the Ozone dataset. This dataset, which predicts ozone levels based on various weather conditions, will help us understand how feature selection techniques can improve environmental models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVBT0mn1xrTI"
      },
      "source": [
        "## Setting Up the Environment\n",
        "Before starting, ensure you have all the required libraries installed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bsgAwdm6xrTI",
        "outputId": "ca046cdb-6513-41b5-8e8a-30bb0f27f6b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.3)\n",
            "Collecting faraway\n",
            "  Downloading faraway-0.0.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
            "Downloading faraway-0.0.6-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faraway\n",
            "Successfully installed faraway-0.0.6\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary libraries\n",
        "%pip install numpy pandas scikit-learn statsmodels faraway"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9mFrraDxrTJ"
      },
      "source": [
        "## Importing the Required Libraries\n",
        "Let's import the libraries we need. These libraries include tools for data manipulation, statistical modeling, and machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FYSWxEhbxrTJ"
      },
      "outputs": [],
      "source": [
        "# Import essential libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "from sklearn import metrics\n",
        "\n",
        "# Import dataset\n",
        "import faraway.datasets.ozone as ozone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yudCsvpyxrTJ"
      },
      "source": [
        "## Loading and Preparing the Dataset\n",
        "We will focus on the Ozone dataset, which contains multiple weather-related variables that we will use to predict ozone levels. We will separate the features X and the target variable y then spit the data into training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Upq_ez-xrTJ"
      },
      "outputs": [],
      "source": [
        "# Load the Ozone dataset\n",
        "data = ozone.load()\n",
        "\n",
        "# Separate features (X) and the target variable (y)\n",
        "X = data.drop(columns=['O3'])\n",
        "y = data['O3']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nij-naGxrTK"
      },
      "source": [
        "## Fitting a Full Model and Analyzing Significance\n",
        "Now that we have our training data, we will start by fitting a simple linear regression model using all available features and then evaluate the significance of each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QyVUNpj5xrTK",
        "outputId": "1fb47f5a-b849-4d63-b686-4a15547a2d93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                     O3   R-squared:                       0.694\n",
            "Model:                            OLS   Adj. R-squared:                  0.683\n",
            "Method:                 Least Squares   F-statistic:                     63.96\n",
            "Date:                Wed, 02 Oct 2024   Prob (F-statistic):           3.08e-60\n",
            "Time:                        18:11:42   Log-Likelihood:                -767.04\n",
            "No. Observations:                 264   AIC:                             1554.\n",
            "Df Residuals:                     254   BIC:                             1590.\n",
            "Df Model:                           9                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         30.3074     33.267      0.911      0.363     -35.207      95.822\n",
            "vh            -0.0072      0.006     -1.181      0.239      -0.019       0.005\n",
            "wind          -0.0839      0.154     -0.545      0.586      -0.387       0.219\n",
            "humidity       0.0742      0.021      3.467      0.001       0.032       0.116\n",
            "temp           0.2674      0.058      4.595      0.000       0.153       0.382\n",
            "ibh           -0.0001      0.000     -0.397      0.692      -0.001       0.001\n",
            "dpg           -0.0006      0.013     -0.049      0.961      -0.026       0.025\n",
            "ibt            0.0359      0.015      2.333      0.020       0.006       0.066\n",
            "vis           -0.0069      0.004     -1.638      0.103      -0.015       0.001\n",
            "doy           -0.0100      0.003     -3.193      0.002      -0.016      -0.004\n",
            "==============================================================================\n",
            "Omnibus:                        1.318   Durbin-Watson:                   2.166\n",
            "Prob(Omnibus):                  0.517   Jarque-Bera (JB):                1.386\n",
            "Skew:                           0.165   Prob(JB):                        0.500\n",
            "Kurtosis:                       2.870   Cond. No.                     7.58e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 7.58e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ],
      "source": [
        "# Add an intercept (constant) to the model\n",
        "X_train = sm.add_constant(X_train)\n",
        "\n",
        "# Fit a multiple linear regression model using all features\n",
        "model_all_features_OLS = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "# Display the summary of the model\n",
        "print(model_all_features_OLS.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haCc-6_cxrTK"
      },
      "source": [
        "* The R-squared value of 0.694 tells us that about 69.4% of the changes in ozone levels (O3) can be explained by the variables we included in the model. This means our model does an ok job, but there's still 30.6% of the ozone variability that it doesn't capture, suggesting there's room to make the model better.\n",
        "\n",
        "* The Adjusted R-squared is slightly lower at 0.683 because it considers the number of variables we used, showing that our model is not the strongest one if we account for complexity.\n",
        "\n",
        "* The F-statistic of 63.96, along with a very tiny p-value (3.08e-60), shows that our overall model is statistically significant, meaning that at least one of the variables is meaningfully linked to O3.\n",
        "\n",
        "This confirms that our model is useful for predicting ozone levels, but there's still potential to refine it further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dpzQBNfxrTK"
      },
      "source": [
        "## Performance of our model\n",
        "Let's focus on the R-squared value of the full model, which measures how well the model explains the variability in the target variable (O3).\n",
        "\n",
        "Then let's predict the ozone levels (O3) using the training data and then evaluating the model's accuracy by calculating the Mean Squared Error (MSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dqZ91Ba5xrTL",
        "outputId": "9604993a-81d3-41db-ccf1-75555a5502ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared = 0.6938475174333434\n",
            "MSE = 19.55081161581369\n"
          ]
        }
      ],
      "source": [
        "# Calculate the R-squared value of the full model\n",
        "R2 = model_all_features_OLS.rsquared\n",
        "print(\"R-squared =\", R2)\n",
        "\n",
        "# Predict values using the training set\n",
        "y_pred_train = model_all_features_OLS.predict(X_train)\n",
        "\n",
        "# Calculate the Mean Squared Error (MSE)\n",
        "MSE = metrics.mean_squared_error(y_train, y_pred_train)\n",
        "print(\"MSE =\", MSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqnHNn6UxrTL"
      },
      "source": [
        "The R-squared value indicates the proportion of the variance explained by the model, and the MSE shows how well the model fits the training data. So there's still room of improvement in the features we are using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ1huaJBxrTL"
      },
      "source": [
        "## Identifying most important features\n",
        "The p-value is a statistical measure that helps us determine whether a variable significantly affects the target variable (O3). A low p-value (typically less than 0.05) suggests that the variable has a significant impact. Let's get these relevant variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d5-Q6lR-xrTL",
        "outputId": "5ddc3a9e-0ddf-4de0-cb19-2935608b508c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Significant Variables: ['humidity', 'temp', 'ibt', 'doy']\n"
          ]
        }
      ],
      "source": [
        "# Extract p-values of the features\n",
        "p_values = model_all_features_OLS.pvalues\n",
        "\n",
        "# Check which variables are significant at the 5% level\n",
        "sigVars = [p_values.iloc[i] < 0.05 for i in range(len(p_values))]\n",
        "variable_names = X_train.columns.tolist()\n",
        "significant_variable_names = [name for name, is_sig in zip(variable_names, sigVars) if is_sig]\n",
        "\n",
        "# Display significant variables\n",
        "print(\"Significant Variables:\", significant_variable_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWBJRMvgxrTL"
      },
      "source": [
        "## Forward Stepwise Selection\n",
        "As we previously defined, Forward stepwise selection involves starting with a model and adding one variable at a time, choosing the variable that improves the model the most.\n",
        "\n",
        "Let's use this along the Adjusted R-squared to get the best combination of features that best represents our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9lCw7AfPxrTL",
        "outputId": "91b03eaf-9c72-41d0-bb30-1ac93d3f721b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusted R-squared of Forward Stepwise Model: 0.9030375117616768\n",
            "Selected Variables: ['humidity', 'temp', 'ibt', 'doy', 'vh', 'vis']\n"
          ]
        }
      ],
      "source": [
        "# Define a function to calculate Adjusted R-squared for a given set of features\n",
        "def calculate_adjusted_r2(X, y):\n",
        "    model_OLS = sm.OLS(y, X).fit()\n",
        "    return model_OLS.rsquared_adj, model_OLS\n",
        "\n",
        "# Select only the significant features for a new model\n",
        "significant_features = X_train.columns[sigVars]\n",
        "X_train_significant_features = X_train[significant_features]\n",
        "\n",
        "# Initialize with significant features\n",
        "selected_vars = list(X_train_significant_features.columns)\n",
        "remaining_vars = [var for var in X_train.columns if var not in selected_vars and var != 'const']\n",
        "\n",
        "# Best model using initial significant features\n",
        "best_adj_r2, best_model = calculate_adjusted_r2(X_train_significant_features, y_train)\n",
        "\n",
        "# Forward Stepwise process: Add variables one at a time\n",
        "while remaining_vars:\n",
        "    adj_r2_with_candidates = []\n",
        "    for candidate in remaining_vars:\n",
        "        # Add candidate variable to the current model\n",
        "        X_candidate = X_train_significant_features.join(X_train[candidate])\n",
        "        adj_r2, model = calculate_adjusted_r2(X_candidate, y_train)\n",
        "        adj_r2_with_candidates.append((adj_r2, candidate, model))\n",
        "\n",
        "    # Sort and select the best candidate variable (higher Adjusted R-squared is better)\n",
        "    adj_r2_with_candidates.sort(reverse=True)  # Sort in descending order to get the highest value\n",
        "    best_new_adj_r2, best_new_var, best_new_model = adj_r2_with_candidates[0]\n",
        "\n",
        "    # Update model if new Adjusted R-squared is higher\n",
        "    if best_new_adj_r2 > best_adj_r2:\n",
        "        selected_vars.append(best_new_var)\n",
        "        X_train_significant_features = X_train_significant_features.join(X_train[best_new_var])\n",
        "        best_adj_r2 = best_new_adj_r2\n",
        "        best_model = best_new_model\n",
        "        remaining_vars.remove(best_new_var)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Display final selected variables and Adjusted R-squared\n",
        "print(\"Adjusted R-squared of Forward Stepwise Model:\", best_adj_r2)\n",
        "print(\"Selected Variables:\", selected_vars)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq0lcjHcxrTM"
      },
      "source": [
        "## Testing the Final Model\n",
        "Finally, we test our model on unseen data (test set) to evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p-ofkpksxrTM",
        "outputId": "2c9d73d9-2b66-4e9f-e2f4-a3c34db8feb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set R-squared = 0.9052412046761842\n",
            "Test Set MSE = 17.658748987607222\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prepare the test set with the selected features\n",
        "X_test = sm.add_constant(X_test)\n",
        "X_test_best_forward_features = X_test[selected_vars]\n",
        "\n",
        "# Predict on the test set\n",
        "pred = best_model.predict(X_test_best_forward_features)\n",
        "\n",
        "R2 = best_model.rsquared\n",
        "print(\"Test Set R-squared =\", R2)\n",
        "\n",
        "# Calculate the MSE on the test set\n",
        "MSEpred = metrics.mean_squared_error(y_test, pred)\n",
        "\n",
        "print(f\"Test Set MSE = {MSEpred}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7qtVpOlxrTM"
      },
      "source": [
        "Our adjusted forward stepwise model, which uses only the most impactful features, has shown improved performance compared to the initial model that included all variables.\n",
        "\n",
        "By honing in on key predictors, we've not only boosted the model's accuracy but also simplified its structure, highlighting the effectiveness of systematic feature selection."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}